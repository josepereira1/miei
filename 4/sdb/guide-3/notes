
My notes:
	Dockerfile: cria uma imagem para um container, sendo que este ficheiro depois é referênciado no docker-compose.yml para ser utilizado como imagem.

	docker-compose.yml: gere os containers de uma máquina para uma respetiva aplicação por exemplo o Zulip, sendo que podemos ter mais do que um docker-compose.yml em uma máquina para diferentes aplicações, por exemplo, ter o Zulip e slack a correrem no mesmo servidor.

	kubernets: gere toda a arquitetura de uma aplicação que pode estar em diferentes máquinas, ou seja, gere diferentes docker-composes.yml da mesma aplicação.

#-----------------------------------------------------------------------------------------------------


https://docs.docker.com/get-started/

What is docker?
Docker is a platform for developers and sysadmins to build, share, and run applications with containers. The use of containers to deploy applications is called containerization. Containers are not new, but their use for easily deploying applications is.


#-----------------------------------------------------------------------------------------------------


Now that we’ve got our orchestrator of choice set up in our development environment thanks to Docker Desktop, we can begin to develop containerized applications. In general, the development workflow looks like this:

Create and test individual containers for each component of your application by first creating Docker images.
Assemble your containers and supporting infrastructure into a complete application, expressed either as a Docker stack file or in Kubernetes YAML.
Test, share and deploy your complete containerized application.


Have a look at the file called Dockerfile. Dockerfiles describe how to assemble a private filesystem for a container, and can also contain some metadata describing how to run a container based on this image. The bulletin board app Dockerfile looks like this:

	FROM node:6.11.5    

	WORKDIR /usr/src/app
	COPY package.json .
	RUN npm install    
	COPY . .

	CMD [ "npm", "start" ] 


Writing a Dockerfile is the first step to containerizing an application. You can think of these Dockerfile commands as a step-by-step recipe on how to build up our image. This one takes the following steps:

Start FROM the pre-existing node:6.11.5 image. This is an official image, built by the node.js vendors and validated by Docker to be a high-quality image containing the node 6.11.5 interpreter and basic dependencies.
Use WORKDIR to specify that all subsequent actions should be taken from the directory /usr/src/app in your image filesystem (never the host’s filesystem).
COPY the file package.json from your host to the present location (.) in your image (so in this case, to /usr/src/app/package.json)
RUN the command npm install inside your image filesystem (which will read package.json to determine your app’s node dependencies, and install them)
COPY in the rest of your app’s source code from your host to your image filesystem.


You can see that these are much the same steps you might have taken to set up and install your app on your host - but capturing these as a Dockerfile allows us to do the same thing inside a portable, isolated Docker image.

The steps above built up the filesystem of our image, but there’s one more line in our Dockerfile. The CMD directive is our first example of specifying some metadata in our image that describes how to run a container based off of this image. In this case, it’s saying that the containerized process that this image is meant to support is npm start.

	My Notes: 
		CMD especifica os comandos a serem executados depois do setup da imagem/container 

What you see above is a good way to organize a simple Dockerfile; always start with a FROM command, follow it with the steps to build up your private filesystem, and conclude with any metadata specifications. There are many more Dockerfile directives than just the few we see above; for a complete list, see the Dockerfile reference.


Build and Test Your Image
Now that we have some source code and a Dockerfile, it’s time to build our first image, and make sure the containers launched from it work as expected.

	1 - Make sure you’re in the directory node-bulletin-board/bulletin-board-app in a terminal or powershell, and build your bulletin board image:
		
		docker image build -t bulletinboard:1.0 .

	2 - Start a container based on your new image:

		docker container run --publish 8000:8080 --detach --name bb bulletinboard:1.0

	We used a couple of common flags here:

		--publish asks Docker to forward traffic incoming on the host’s port 8000, to the container’s port 8080 (containers have their own private set of ports, so if we want to reach one from the network, we have to forward traffic to it in this way; otherwise, firewall rules will prevent all network traffic from reaching your container, as a default security posture).
		--detach asks Docker to run this container in the background.
		--name lets us specify a name with which we can refer to our container in subsequent commands, in this case bb.
		Also notice, we didn’t specify what process we wanted our container to run. We didn’t have to, since we used the CMD directive when building our Dockerfile; thanks to this, Docker knows to automatically run the process npm start inside our container when it starts up.


#-----------------------------------------------------------------------------------------------------

What is docke swarm?

Now that we’ve demonstrated that the individual components of our application run as stand-alone containers and shown how to deploy it using Kubernetes, let’s look at how to arrange for them to be managed by Docker Swarm. Swarm provides many tools for scaling, networking, securing and maintaining your containerized applications, above and beyond the abilities of containers themselves.

In order to validate that our containerized application works well on Swarm, we’ll use Docker Desktop’s built in Swarm environment right on our development machine to deploy our application, before handing it off to run on a full Swarm cluster in production. The Swarm environment created by Docker Desktop is fully featured, meaning it has all the Swarm features your app will enjoy on a real cluster, accessible from the convenience of your development machine.

Describing Apps Using Stack Files

Swarm never creates individual containers like we did in the previous step of this tutorial; instead, all Swarm workloads are scheduled as services, which are scalable groups of containers with added networking features maintained automatically by Swarm. Furthermore, all Swarm objects can and should be described in manifests called stack files; these YAML files describe all the components and configurations of your Swarm app, and can be used to easily create and destroy your app in any Swarm environment.


Let’s write a simple stack file to run and manage our bulletin board. Place the following in a file called bb-stack.yaml:

	version: '3.7'    

	services:
	  bb-app:
	    image: bulletinboard:1.0
	    ports:
	      - "8000:8080"

In this Swarm YAML file, we have just one object: a service, describing a scalable group of identical containers. In this case, you’ll get just one container (the default), and that container will be based off of your bulletinboard:1.0 image from step 2 of this tutorial. We’ve furthermore asked Swarm to forward all traffic arriving at port 8000 on our development machine to port 8080 inside our bulletin board container.


Deploying and Checking Your Application

	Deploy your application to Swarm:

		docker stack deploy -c bb-stack.yaml demo

	Make sure everything worked by listing your service:

		docker service ls

	Once satisfied, tear down your application:

		docker stack rm demo

#-----------------------------------------------------------------------------------------------------

The Difference Between Docker Compose And Docker Stack ???

In recent releases, a few things have happened in the Docker world. Swarm mode got integrated into the Docker Engine in 1.12, and has brought with it several new tools. Among others, it’s possible to make use of docker-compose.yml files to bring up stacks of Docker containers, without having to install Docker Compose.

The command is called docker stack, and it looks exactly the same to docker-compose. Here’s a comparison:

	$ docker-compose -f docker-compose up

	$ docker stack deploy -c docker-compose.yml somestackname

Pretty similar indeed. Both of those will bring up all the services, volumes, networks and everything else, just as specified in docker-compose.yml files. But why has this happened, and is docker stack different from Docker Compose somehow? Why was it introduced? What to mind, apart from the syntax?

The Difference
Docker stack is ignoring “build” instructions. You can’t build new images using the stack commands. It need pre-built images to exist. So docker-compose is better suited for development scenarios.

There are also parts of the compose-file specification which are ignored by docker-compose or the stack commands. (Search for “ignore” on that page to look through more details).


